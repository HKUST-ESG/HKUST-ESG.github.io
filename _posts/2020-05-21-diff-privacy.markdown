---
layout: post
title: "Differential Privacy"
author: "Lavanya Singh"
presenter: "Lavanya Singh"
date:  2020-05-21
categories: [privacy, algorithms, theory]
papers:
- name: "Differential Privacy: A Survey of Results"
  link: "https://web.cs.ucdavis.edu/~franklin/ecs289/2010/dwork_2008.pdf"
- name: "Calibrating Noise to Sensitivity in Private Data Analysis"
  link: "https://people.csail.mit.edu/asmith/PS/sensitivity-tcc-final.pdf"
- name: "Stanford CS229 Learning Theory Notes"
  link: "http://cs229.stanford.edu/summer2020/cs229-notes4.pdf"
---

## Inspiration
Look, I just think differential privacy is really cool. 

## Papers

The first paper we read was "Calibrating Noise to Sensitivity in Private Data Analysis," the
original differential privacy paper. We spent most of our time and attention on "Differential
Privacy: A Survey of Results." The end of the survey discusses some results from learning 
theory, and we used Stanford CS229's notes part 6 as a brief introduction to learning theory.

## Discussion

These papers have a lot of math in them, and we spent most of the session wrapping our heads 
around the proofs presented. This was one of our first meetings, and I had no experience with 
statistics or learning theory before the session. 

We also discussed choice of the privacy budget \epsilon and with the idea of a "trusted database
curator." Differential privacy is a powerful guarantee, but if your curator is a large technology
company, then we might not trust them to care about our privacy.

## Tangents

Many months after our discussion, Professor Cynthia Dwork won the Knuth Prize, and Harvard CS was
invited to watch her lecture! Check out her lecture [here](https://www.youtube.com/watch?v=2wLNgSaLb8A).



